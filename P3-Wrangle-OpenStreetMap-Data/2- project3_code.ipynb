{"nbformat": 4, "metadata": {"kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}, "language_info": {"version": "3.4.3", "name": "python", "mimetype": "text/x-python", "nbconvert_exporter": "python", "file_extension": ".py", "pygments_lexer": "ipython3", "codemirror_mode": {"version": 3, "name": "ipython"}}}, "nbformat_minor": 0, "cells": [{"source": "#OpenStreetMap Project - Code", "metadata": {}, "cell_type": "markdown"}, {"source": "# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Thu Mar 17 15:45:00 2016\n@author: David Shahrestani\n\"\"\"\n\n#Load Libraries for project\nimport xml.etree.cElementTree as ET\nimport pprint\nimport re\nfrom collections import defaultdict\nimport codecs\nimport json\nfrom pymongo import MongoClient\nimport operator\nimport os\n\n#Set up path for OSM file\nFILENAME = \"c:\\\\users\\\\david shahrestani\\\\downloads\\\\data wrang temp\\\\project\\\\santa-barbara.osm\"\nFILENAMEJSON = \"c:\\\\users\\\\david shahrestani\\\\downloads\\\\data wrang temp\\\\project\\\\santa-barbara.osm.json\"\n\n#Set up regular expressions for project\nlower = re.compile(r'^([a-z]|_)*$')\nlower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\nstreet_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\npostal_code_re = re.compile(r'(\\d{5})-\\d{4}')\npostal_code_re2 = re.compile(r'(\\d{5}):\\d{5}')\nproblemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')", "metadata": {"collapsed": false, "trusted": true}, "execution_count": 1, "outputs": [], "cell_type": "code"}, {"source": "\"\"\"\nYour task is to use the iterative parsing to process the map file and\nfind out not only what tags are there, but also how many, to get the\nfeeling on how much of which data you can expect to have in the map.\nFill out the count_tags function. It should return a dictionary with the \ntag name as the key and number of times this tag can be encountered in \nthe map as value.\n\nNote that your code will be tested with a different data file than the 'example.osm'    \n\"\"\"\n\ndef add_tag(tag, tag_count):\n    \"\"\"Initialize or add a tag to tag_count\"\"\"\n    if tag in tag_count:\n        tag_count[tag] += 1\n    else:\n        tag_count[tag] = 1\n\n        \ndef count_tags(filename):\n    \"\"\"Count tags in OSM file and print them out\"\"\"\n    tag_count = {}\n    tag_keys = {}\n    counter = 0\n\n    for _, element in ET.iterparse(filename, events=(\"start\",)):\n        add_tag(element.tag, tag_count)\n        if element.tag == 'tag' and 'k' in element.attrib:\n            add_tag(element.get('k'), tag_keys)\n\n    tag_keys = sorted(tag_keys.items(), key=operator.itemgetter(1))[::-1]\n    \n    return tag_count, tag_keys\n\n\nprint(count_tags(FILENAME))", "metadata": {"collapsed": false, "trusted": true, "scrolled": true}, "execution_count": 3, "outputs": [{"name": "stdout", "output_type": "stream", "text": "({'way': 36508, 'tag': 296648, 'bounds': 1, 'relation': 355, 'nd': 938528, 'member': 8759, 'osm': 1, 'node': 836124}, [('highway', 22919), ('name', 16976), ('tiger:county', 16732), ('tiger:cfcc', 16723), ('tiger:reviewed', 15035), ('tiger:tlid', 14869), ('tiger:source', 14763), ('tiger:separated', 13023), ('tiger:name_base', 11900), ('source', 10991), ('tiger:name_type', 10552), ('waterway', 7505), ('tiger:zip_left', 7496), ('tiger:zip_right', 7090), ('tiger:upload_uuid', 6064), ('attribution', 4612), ('nhd:com_id', 3925), ('gnis:fcode', 3925), ('nhd:fdate', 3924), ('nhd:reach_code', 3894), ('gnis:ftype', 3758), ('building', 3480), ('NHD:ReachCode', 3005), ('NHD:FCode', 3005), ('NHD:FType', 2997), ('intermittent', 2864), ('NHD:ComID', 2821), ('NHD:RESOLUTION', 2811), ('NHD:way_id', 2811), ('oneway', 2804), ('landuse', 2148), ('created_by', 2095), ('amenity', 1821), ('access', 1775), ('power', 1694), ('service', 1580), ('tiger:name_direction_prefix', 1502), ('ele', 1394), ('bicycle', 1352), ('gnis:feature_id', 1216), ('gnis:id', 1150), ('ref', 1093), ('gnis:created', 1086), ('nhd:way_id', 1046), ('source_ref', 1013), ('gnis:county_id', 1007), ('gnis:state_id', 1007), ('natural', 931), ('tiger:name_base_1', 877), ('lanes', 716), ('addr:county', 704), ('FMMP_modified', 698), ('FMMP_reviewed', 698), ('leisure', 656), ('addr:housenumber', 645), ('addr:street', 640), ('hgv', 603), ('hgv:national_network', 518), ('source:hgv:national_network', 506), ('operator', 444), ('name_1', 437), ('surface', 431), ('bridge', 408), ('foot', 406), ('railway', 405), ('type', 398), ('description', 393), ('layer', 387), ('maxspeed', 371), ('shelter', 348), ('NHS', 335), ('barrier', 335), ('tiger:name_base_2', 325), ('tiger:zip_left_1', 315), ('bench', 313), ('man_made', 306), ('acres', 300), ('religion', 294), ('shop', 254), ('note', 244), ('addr:state', 240), ('tiger:name_type_1', 235), ('emergency', 234), ('Source', 222), ('Tiger:MTFCC', 220), ('longitude', 219), ('latitude', 219), ('place', 212), ('gnis:county_name', 209), ('addr:city', 203), ('gauge', 176), ('is_in', 175), ('water', 172), ('tiger:STATEFP', 163), ('tiger:zip_right_1', 162), ('source:lanes', 160), ('source_ref:maxspeed', 158), ('source:maxspeed', 158), ('addr:postcode', 157), ('cycleway', 155), ('old_ref', 154), ('image_direction', 152), ('AREAID', 142), ('AWATER', 137), ('ALAND', 137), ('MTFCC', 137), ('aeroway', 136), ('tourism', 134), ('COUNTYFP', 134), ('STATEFP', 134), ('sport', 132), ('tiger:AWATER', 131), ('tiger:ALAND', 131), ('tiger:AREAID', 131), ('tiger:COUNTYFP', 131), ('gnis:import_uuid', 127), ('gnis:Class', 126), ('import_uuid', 126), ('gnis:ST_num', 126), ('gnis:ST_alpha', 126), ('gnis:County_num', 126), ('gnis:County', 126), ('cuisine', 125), ('gnis:reviewed', 125), ('denomination', 120), ('phone', 117), ('addr:country', 114), ('is_in:state_code', 112), ('restriction', 106), ('payment:coins', 96), ('image', 95), ('phone:incoming', 94), ('boundary', 86), ('route', 85), ('area', 84), ('floating', 82), ('tiger:MTFCC', 81), ('parking', 81), ('gnis:feature_type', 79), ('tiger:name_type_2', 79), ('tiger:zip_left_2', 78), ('network', 77), ('noexit', 70), ('seamark', 67), ('admin_level', 67), ('cables', 66), ('website', 66), ('source:hgv:state_network', 64), ('hgv:state_network', 64), ('motor_vehicle', 60), ('milepost:county', 60), ('wikipedia', 58), ('building:levels', 57), ('FIXME', 55), ('direction', 54), ('color', 52), ('fee', 52), ('roundtrip', 52), ('light', 50), ('light:signal_period', 50), ('light:character', 50), ('light:colour', 49), ('seamark:ref', 48), ('tunnel', 46), ('buoy', 46), ('buoy:shape', 45), ('source:bridge', 45), ('wheelchair', 42), ('buoy:colour', 42), ('bridge_ref', 40), ('bridge_name', 40), ('tracktype', 40), ('park:type', 40), ('source_ref:lanes', 38), ('is_in:state', 38), ('sidewalk', 37), ('tiger:name_direction_prefix_1', 37), ('tiger:zip_right_2', 36), ('is_in:country', 35), ('disused', 35), ('place_name', 34), ('designation', 33), ('tiger:PCICBSA', 33), ('tiger:NAME', 33), ('tiger:LSAD', 33), ('tiger:NAMELSAD', 33), ('tiger:PLACENS', 33), ('tiger:PCINECTA', 33), ('tiger:CPI', 33), ('is_in:country_code', 33), ('tiger:PLACEFP', 33), ('tiger:FUNCSTAT', 33), ('is_in:iso_3166_2', 33), ('tiger:CLASSFP', 33), ('tiger:PLCIDFP', 33), ('csp:globalid', 32), ('csp:unitcode', 32), ('junction', 32), ('source:cycleway', 31), ('alt_name', 30), ('crossing', 29), ('seamark:type', 29), ('loc_name', 29), ('light:range', 28), ('voltage', 28), ('frequency', 28), ('border_type', 27), ('tiger:name_direction_suffix', 27), ('tiger:zip_left_3', 26), ('brand', 26), ('capacity', 25), ('source:pkey', 25), ('source_ref:bridge', 24), ('odbl', 24), ('monitoring:water_level', 24), ('source:website', 24), ('capacity:disabled', 24), ('source:ref', 23), ('source_ref:ref', 23), ('width', 23), ('construction', 22), ('source_ref:cycleway', 22), ('source:position', 21), ('building:color', 21), ('building:material', 21), ('height', 20), ('motorcar', 20), ('fixme', 20), ('beacon:shape', 19), ('field_name', 19), ('is_in:county', 19), ('light:height', 19), ('beacon', 18), ('office', 18), ('topmark:colour', 18), ('colour', 18), ('bearing', 18), ('topmark:shape', 18), ('topmark', 18), ('addr:street_direction_prefix', 17), ('atm', 17), ('maxspeed:hgv', 17), ('level', 17), ('maxspeed:towing', 17), ('beacon:colour', 17), ('wetland', 17), ('name_2', 16), ('horse', 16), ('roof:material', 16), ('roof:color', 16), ('opening_hours', 15), ('historic', 15), ('nist:fips_code', 14), ('exit_to', 14), ('sac_scale', 14), ('source:maxspeed:hgv', 13), ('routes', 13), ('source_ref:hgv', 13), ('source_ref:maxspeed:hgv', 13), ('source:maxspeed:towing', 13), ('population', 13), ('source:hgv', 13), ('source_ref:maxspeed:towing', 13), ('street', 13), ('ownership', 11), ('gnis:edited', 11), ('protection_title', 11), ('roof:shape', 11), ('electrified', 11), ('odbl:note', 11), ('traffic_calming', 11), ('FIXME:bicycle', 11), ('boundary:type', 11), ('fuel:diesel', 11), ('noref', 10), ('tiger:zip_right_3', 10), ('housing_type', 10), ('building:part', 10), ('maxspeed:advisory', 10), ('tracks', 10), ('site', 10), ('seamark:name', 9), ('maxspeed:children_present', 9), ('addr:full', 9), ('note:lanes', 9), ('wikipedia:en', 9), ('use', 9), ('caltrans:district', 8), ('NHD:FDate', 8), ('NHD:FTYPE', 8), ('NHD:Resolution', 8), ('addr:unit', 8), ('roof:levels', 8), ('addr:housename', 8), ('icao', 8), ('buoy:text', 8), ('NHD:Permanent_', 8), ('old_name', 8), ('iata', 8), ('roof:height', 8), ('tiger:zip_left_4', 8), ('enforcement', 7), ('fog_signal', 7), ('seamark:small_craft_facility:category', 7), ('light:signal_group', 7), ('source:oneway', 7), ('census:population', 7), ('seamark:information', 7), ('tiger:name_base_3', 7), ('symbol', 7), ('protect_class', 6), ('GIS_ACRES', 6), ('outdoor_seating', 6), ('source_ref:maxspeed:advisory', 6), ('SHAPE_Area', 6), ('traffic_sign', 6), ('SHAPE_Leng', 6), ('hgv:minweight', 6), ('source:maxspeed:advisory', 6), ('seamark:light:colour', 6), ('name:ar', 6), ('drive_through', 5), ('covered', 5), ('maxweight', 5), ('internet_access', 5), ('BOUNDARYST', 5), ('seamark:light:character', 5), ('military', 5), ('caltrans:type', 5), ('length', 5), ('protected', 5), ('source:maxspeed:children_present', 5), ('public_transport', 5), ('source_ref:maxspeed:children_present', 5), ('official_name', 5), ('tiger:name_type_3', 5), ('protect_id', 5), ('caltrans:dynsegpm', 5), ('WILDERNESS', 5), ('dispensing', 5), ('source:maxweight', 4), ('circuits', 4), ('seamark:light:1:radius', 4), ('parking:lane:both', 4), ('collection_times', 4), ('seamark:light:1:colour', 4), ('fog_signal:signal_period', 4), ('source_ref:maxweight', 4), ('seamark:light:1:sector_end', 4), ('name:en', 4), ('seamark:light:1:sector_start', 4), ('key', 4), ('crane:type', 4), ('artist_name', 4), ('wires', 4), ('faa', 3), ('objectid', 3), ('st_area_sh', 3), ('embankment', 3), ('ford', 3), ('park_ride', 3), ('name:he', 3), ('information', 3), ('closest_town', 3), ('seamark:light:1:character', 3), ('implied', 3), ('modifier', 3), ('owner', 3), ('route_ref', 3), ('tiger:zip_right_4', 3), ('name:af', 3), ('seamark:light:1:range', 3), ('courts', 3), ('fenced', 3), ('start_date', 3), ('seamark:reference', 3), ('seamark:light:1:height', 3), ('seamark:light:1:period', 3), ('nets', 3), ('vending', 3), ('toilets', 3), ('delivery', 3), ('st_length_', 3), ('name:da', 3), ('min_height', 3), ('seamark:status', 3), ('tiger:name_direction_prefix_2', 3), ('name:bn', 2), ('source_ref:daytime_headlight', 2), ('payment:bitcoin', 2), ('name:os', 2), ('name:sr', 2), ('artwork_type', 2), ('maxheight', 2), ('name:el', 2), ('name:kw', 2), ('name:pt', 2), ('name:ko', 2), ('acreage', 2), ('note_1', 2), ('county:name', 2), ('produce', 2), ('name:mn', 2), ('name:mg', 2), ('pet_area', 2), ('note:ref', 2), ('name:ht', 2), ('name:az', 2), ('ref:right', 2), ('name:de', 2), ('county:ansi', 2), ('handicapped_accessible', 2), ('name:sh', 2), ('name:nv', 2), ('seamark:fog_signal:period', 2), ('name:bg', 2), ('name:ca', 2), ('leading:angle', 2), ('name:sv', 2), ('name:fi', 2), ('name:hi', 2), ('automated', 2), ('seamark:fog_signal:category', 2), ('boundary_type', 2), ('takeaway', 2), ('sanitation', 2), ('seamark:light:range', 2), ('name:ta', 2), ('source:daytime_headlight', 2), ('seamark:building:function', 2), ('name:haw', 2), ('is_in:continent', 2), ('disabled_spaces', 2), ('name:be', 2), ('name:szl', 2), ('name:ja', 2), ('name:eo', 2), ('name:cs', 2), ('name:sl', 2), ('nist:state_fips', 2), ('name:hy', 2), ('name:nl', 2), ('step_count', 2), ('name:zh', 2), ('name:lt', 2), ('name:hu', 2), ('name:eu', 2), ('picnic_tables', 2), ('name:iu', 2), ('name:ru', 2), ('name:tl', 2), ('name:cy', 2), ('basin', 2), ('name:uk', 2), ('name:th', 2), ('name:fa', 2), ('self_service', 2), ('name:kn', 2), ('name:br', 2), ('name:mi', 2), ('name:fy', 2), ('name:sk', 2), ('generator:output:electricity', 2), ('name:hr', 2), ('name:tr', 2), ('maritime', 2), ('daytime_headlight', 2), ('name:cv', 2), ('drinking_water', 2), ('occurrence', 2), ('name:oc', 2), ('name:es', 2), ('name:yi', 2), ('alt_name:vi', 2), ('name:hak', 2), ('name:is', 2), ('name:gd', 2), ('name:mr', 2), ('name:fr', 2), ('source_ref:oneway', 2), ('generator:source', 2), ('name:ml', 2), ('name:vi', 2), ('seamark:light:reference', 2), ('url', 2), ('smoking', 2), ('light:signal_sequence', 2), ('name:fo', 2), ('seamark:light:height', 2), ('name_3', 2), ('name:ka', 2), ('section', 2), ('name:uz', 2), ('seamark:light:period', 2), ('name:pl', 2), ('county:abbrev', 2), ('name:ug', 1), ('timezone', 1), ('fuel:1_25', 1), ('name:tet', 1), ('pool', 1), ('Operator', 1), ('name:arz', 1), ('seamark:landmark:colour', 1), ('name:chr', 1), ('name:bi', 1), ('name:wuu', 1), ('name:ky', 1), ('name:csb', 1), ('name:war', 1), ('pedestrian', 1), ('recreation', 1), ('name:srn', 1), ('name:dsb', 1), ('fuel:cng', 1), ('name:bs', 1), ('bicycle:backward', 1), ('fuel:e85', 1), ('name:am', 1), ('name:eml', 1), ('screen', 1), ('source:name', 1), ('name:li', 1), ('contact:phone', 1), ('name:lb', 1), ('name:km', 1), ('recycling:oil', 1), ('name:zh-classical', 1), ('name:bo', 1), ('name:fiu-vro', 1), ('water_type', 1), ('harbour', 1), ('hours', 1), ('stairs', 1), ('open_date', 1), ('name:lv', 1), ('name.old', 1), ('name:ms', 1), ('name:su', 1), ('name:tg', 1), ('Name', 1), ('name:ie', 1), ('name:za', 1), ('name:ts', 1), ('species', 1), ('ISO3166-1', 1), ('name:se', 1), ('variation', 1), ('name:frr', 1), ('name:ce', 1), ('barrier:security', 1), ('name:ig', 1), ('name:kbd', 1), ('name:cbk-zam', 1), ('name:diq', 1), ('ADMINFORES', 1), ('nudity', 1), ('name:mzn', 1), ('name:mhr', 1), ('fuel:1_50', 1), ('short_name:vi', 1), ('name:pap', 1), ('name:cdo', 1), ('name:bpy', 1), ('name:kaa', 1), ('kerb', 1), ('beacon:text', 1), ('name:pfl', 1), ('name:vep', 1), ('name:nap', 1), ('name:sn', 1), ('name:ks', 1), ('hist_ref', 1), ('source:maxheight', 1), ('name:wa', 1), ('name:ki', 1), ('tiger:name_base_4', 1), ('name:to', 1), ('name:fur', 1), ('name:nds-nl', 1), ('name:gag', 1), ('recycling:asphalt', 1), ('note_2', 1), ('name:ga', 1), ('fuel:octane_100', 1), ('maxstay', 1), ('seamark:light:1:group', 1), ('vegetarian', 1), ('name:rue', 1), ('name:sg', 1), ('REGION', 1), ('name:pa', 1), ('name:om', 1), ('name:krc', 1), ('channel', 1), ('recycling:concrete', 1), ('name:lo', 1), ('lot_no', 1), ('name:bar', 1), ('barrier:personnel', 1), ('name:pnb', 1), ('train', 1), ('name:ff', 1), ('name:sc', 1), ('tiger:name_direction_suffix_4', 1), ('name:nah', 1), ('private', 1), ('ref:fips', 1), ('name:tpi', 1), ('name:jv', 1), ('name:sw', 1), ('name:nn', 1), ('fence_type', 1), ('name:ro', 1), ('bicycle:forward', 1), ('name:ia', 1), ('name:an', 1), ('ref:left', 1), ('fuel:biogas', 1), ('name:bat-smg', 1), ('name:ilo', 1), ('last_edite', 1), ('name:tt', 1), ('seamark:light:group', 1), ('name:my', 1), ('name:ace', 1), ('name:rn', 1), ('monitoring_station', 1), ('id', 1), ('name:chy', 1), ('name:ku', 1), ('radar', 1), ('location', 1), ('name:pih', 1), ('port_of_entry', 1), ('name:lmo', 1), ('accuracy', 1), ('name:kv', 1), ('name:la', 1), ('name:te', 1), ('name:ext', 1), ('flag', 1), ('name:sq', 1), ('tiger:name_type_4', 1), ('name:zh-min-nan', 1), ('name:bm', 1), ('name:et', 1), ('population:source', 1), ('name:na', 1), ('name:kl', 1), ('name:gl', 1), ('name:pam', 1), ('name:ba', 1), ('urgent_care', 1), ('name:gan', 1), ('name:lbe', 1), ('name:sco', 1), ('fuel:HGV_diesel', 1), ('name:nrm', 1), ('seamark:landmark:category', 1), ('fullcourt', 1), ('name:tk', 1), ('name:yo', 1), ('fuel:e10', 1), ('name:vec', 1), ('name:ln', 1), ('quantity', 1), ('name:ne', 1), ('name:nov', 1), ('name:so', 1), ('name:ast', 1), ('fuel:lpg', 1), ('bus', 1), ('name:udm', 1), ('name:min', 1), ('tower:type', 1), ('name:ltg', 1), ('name:simple', 1), ('name:lg', 1), ('name:arc', 1), ('name:io', 1), ('name:ckb', 1), ('name:ur', 1), ('name:ik', 1), ('name:scn', 1), ('Dry Canyon Road', 1), ('name:or', 1), ('brewery', 1), ('name:glk', 1), ('name:rw', 1), ('int_name', 1), ('name:koi', 1), ('fuel:GTL_diesel', 1), ('name:wo', 1), ('name:kab', 1), ('name:dz', 1), ('objectid_1', 1), ('official_name:vi', 1), ('seamark:light:sequence', 1), ('name:mrj', 1), ('name:hif', 1), ('ao', 1), ('name:ee', 1), ('name:mdf', 1), ('name:sah', 1), ('tiger:name_direction_prefix_3', 1), ('name:hsb', 1), ('short_name', 1), ('name:ksh', 1), ('name:roa-tara', 1), ('name:bxr', 1), ('name:no', 1), ('name:id', 1), ('name:bcl', 1), ('old_name:vi', 1), ('name:as', 1), ('last_edi_1', 1), ('wifi', 1), ('name:xh', 1), ('name:xal', 1), ('wpt_description', 1), ('name:kk', 1), ('name:nso', 1), ('name:lez', 1), ('collection', 1), ('name:it', 1), ('ft_link', 1), ('footway', 1), ('FORESTNUMB', 1), ('name:qu', 1), ('name_4', 1), ('name:pms', 1), ('name:map-bms', 1), ('source_ref:maxheight', 1), ('status', 1), ('name:crh', 1), ('name:new', 1), ('name:pcd', 1), ('name:pag', 1), ('name:nds', 1), ('FORESTORGC', 1), ('cinema:3D', 1), ('seamark:light:1:sequence', 1), ('relation', 1), ('name:zu', 1), ('name:myv', 1), ('name:ang', 1), ('vegan', 1), ('name:lad', 1), ('name:vo', 1), ('name:tn', 1), ('name:mt', 1), ('MDA', 1), ('name:rm', 1), ('name:gv', 1), ('name:ps', 1), ('name:sd', 1), ('name:jbo', 1), ('segregated', 1), ('name:zh-yue', 1), ('name:cu', 1), ('fuel:electricity', 1), ('name:xmf', 1), ('name:als', 1), ('name:gn', 1), ('name:mwl', 1), ('caltrans:pctuse', 1), ('cycleway:right', 1), ('name:lij', 1), ('name:co', 1), ('name:mk', 1), ('name:ab', 1), ('name:vls', 1), ('name:av', 1), ('branch_type', 1), ('name:sm', 1), ('name:ha', 1), ('name:stq', 1), ('name:gu', 1), ('name:ty', 1), ('seamark:beacon_lateral:category', 1), ('name:zea', 1), ('name:ay', 1), ('addr:even', 1), ('name:ceb', 1), ('category', 1), ('name:ss', 1), ('end_date', 1), ('name:be-x-old', 1), ('seamark:beacon_lateral:colour', 1), ('name:dv', 1), ('high', 1), ('name:pdc', 1), ('name:sa', 1), ('addr:odd', 1), ('seamark:beacon_lateral:system', 1), ('name:tw', 1), ('fog_signal:signal_group', 1), ('name:frp', 1), ('name:si', 1), ('depth', 1), ('fuel:biodiesel', 1)])\n"}], "cell_type": "code"}, {"source": "\"\"\"\nYour task is to explore the data a bit more.\nBefore you process the data and add it into MongoDB, you should\ncheck the \"k\" value for each \"<tag>\" and see if they can be valid keys in MongoDB,\nas well as see if there are any other potential problems.\n\nWe have provided you with 3 regular expressions to check for certain patterns\nin the tags. As we saw in the quiz earlier, we would like to change the data model\nand expand the \"addr:street\" type of keys to a dictionary like this:\n{\"address\": {\"street\": \"Some value\"}}\nSo, we have to see if we have such tags, and if we have any tags with problematic characters.\nPlease complete the function 'key_type'.\n\"\"\"\n\ndef key_type(element, keys):\n    \"\"\"Check \"k\" values against provided reg expressions\"\"\"\n    if element.tag == \"tag\":\n        k_value = element.attrib['k']\n        if lower.search(k_value) is not None:\n            keys['lower'] += 1\n        elif lower_colon.search(k_value) is not None:\n            keys['lower_colon'] += 1\n        elif problemchars.search(k_value) is not None:\n            keys[\"problemchars\"] += 1\n        else:\n            keys['other'] += 1\n\n    return keys\n\n    \ndef process_map_keys(filename):\n    \"\"\"Process the OSM file to find key issues\"\"\"\n    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n    \n    for _, element in ET.iterparse(filename):\n        keys = key_type(element, keys)\n\n    return keys\n\n\nprint(process_map_keys(FILENAME))", "metadata": {"collapsed": false, "trusted": true}, "execution_count": 13, "outputs": [{"name": "stdout", "output_type": "stream", "text": "{'lower_colon': 168200, 'problemchars': 2, 'lower': 102666, 'other': 25780}\n"}], "cell_type": "code"}, {"source": "\"\"\"\nYour task is to explore the data a bit more.\nThe first task is a fun one - find out how many unique users\nhave contributed to the map in this particular area!\n\nThe function process_map should return a set of unique user IDs (\"uid\")\n\"\"\"\n\ndef process_map_users(filename):\n    \"\"\"Process the OSM file to find out how many unique user ID's there are\"\"\"\n    users = set()\n    \n    for _, element in ET.iterparse(filename):\n        if element.tag == \"node\" or element.tag == \"way\" or element.tag == \"relation\":\n            users.add(element.attrib['uid'])\n\n    return users\n\n\nprint(process_map_users(FILENAME))", "metadata": {"collapsed": false, "trusted": true}, "execution_count": 14, "outputs": [{"name": "stdout", "output_type": "stream", "text": "{'1807684', '86938', '13241', '156520', '92274', '537938', '82317', '78656', '65950', '468200', '330773', '6879', '86782', '42191', '76002', '406005', '191585', '416346', '186058', '36121', '331085', '244743', '1679', '399973', '36489', '5359', '478074', '30554', '576986', '1711421', '188295', '16150', '996997', '14512', '228596', '13832', '308', '618879', '24452', '110263', '161798', '123633', '894660', '409086', '26299', '22773', '15891', '70696', '7591', '1225676', '408189', '55774', '9065', '1374669', '4732', '129255', '238349', '279960', '401102', '35900', '39839', '595221', '112530', '78918', '113450', '123364', '582561', '314684', '6681', '625109', '10786', '442739', '1529374', '232126', '207488', '153669', '473471', '54759', '100405', '318696', '645457', '155969', '1822223', '68842', '119881', '941876', '1193667', '122516', '262151', '476841', '147510', '89813', '128186', '20587', '204153', '360392', '303120', '28794', '235701', '481531', '31231', '163231', '186617', '110046', '355242', '1719731', '356014', '135329', '159170', '235708', '296359', '774597', '178626', '89943', '1058658', '236239', '648374', '11154', '224440', '24920', '90780', '131059', '722137', '414318', '207745', '441542', '121241', '330761', '432840', '401105', '346', '50743', '181135', '354006', '574654', '225326', '394224', '235702', '7168', '190389', '129061', '13840', '38487', '51045', '46789', '1196363', '1204409', '402709', '988092', '125718', '52959', '296520', '14293', '568928', '290680', '48060', '39504', '60345', '60744', '1833145', '97440', '160138', '63107', '408202', '338476', '379381', '36894', '3516', '42429', '689176', '1655294', '158537', '65148', '612402', '234358', '507262', '846445', '42619', '237335', '73268', '2376', '1545678', '3582', '1698742', '416323', '1494360', '222635', '217070', '37392', '615700', '1198074', '149748', '532783', '586964', '79401', '315015', '1725109', '167009', '45263', '88337', '475877', '3962', '67862', '5616', '28145', '45027', '1805532', '293424', '235703', '227414', '1442345', '6975', '158636', '1694880', '305579', '18480', '440098', '42123', '254704', '1799793', '89204', '38985', '12448', '319166', '182536', '351026', '633337', '214969', '129349', '55958', '194231', '53073', '100243', '343390', '451693', '1739938', '1314388', '837425', '1376118', '166129', '3614', '103253', '1779796', '62224', '1355899', '104962', '15398', '1769166', '13303', '28923', '82820', '486544', '131476', '38239', '51581', '3392', '339764', '3158', '170672', '20783', '1750455', '1247632', '631711', '17490', '856345', '178186', '351693', '4951', '263605', '1212907', '593205', '169004', '161269', '34411', '8561', '1820999', '22916', '53936', '1494110', '19235', '435051', '510836', '18069', '355127', '10849', '549487', '25510', '28775', '678132', '597941', '165869', '1802596', '110639', '779232', '1123669', '1433171', '113375', '323496'}\n"}], "cell_type": "code"}, {"source": "\"\"\"\nYour task in this exercise has two steps:\n\n- audit the OSMFILE and change the variable 'mapping' to reflect the changes needed to fix \n    the unexpected street types to the appropriate ones in the expected list.\n    You have to add mappings only for the actual problems you find in this OSMFILE,\n    not a generalized solution, since that may and will depend on the particular area you are auditing.\n- write the update_name function, to actually fix the street name.\n    The function takes a string with street name as an argument and should return the fixed name\n    We have provided a simple test so that you see what exactly is expected\n\"\"\"\n\n#expected street types\nexpected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n            \"Trail\", \"Parkway\", \"Commons\"]\n\ndef audit_street_type(street_types, street_name):\n    m = street_type_re.search(street_name)\n    \n    if m:\n        street_type = m.group()\n        if street_type not in expected:\n            street_types[street_type].add(street_name)\n\n\ndef is_street_name(elem):\n    return (elem.attrib['k'] == \"addr:street\")\n\n\ndef audit(osmfile):\n    \"\"\"Audit the OSM file for street types that are not expected\"\"\"\n    osm_file = open(osmfile, \"r\", encoding=\"utf8\")\n    street_types = defaultdict(set)\n    \n    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n        if elem.tag == \"node\" or elem.tag == \"way\":\n            for tag in elem.iter(\"tag\"):\n                if is_street_name(tag):\n                    audit_street_type(street_types, tag.attrib['v'])\n                                        \n    return street_types\n\n\nstreet_types = audit(FILENAME)\npprint.pprint(dict(street_types))", "metadata": {"collapsed": false, "trusted": true, "scrolled": true}, "execution_count": 2, "outputs": [{"name": "stdout", "output_type": "stream", "text": "{'101': {'North Highway 101'},\n '154': {'Jct Of Sr 246 & Sr 154'},\n '30.12': {'Hwy 33 PM 30.12'},\n 'Abrego': {'Abrego'},\n 'Ave': {'Lillie Ave',\n         'Linden Ave',\n         'Los Angeles Ave',\n         'N Ashwood Ave',\n         'N Ventura Ave',\n         'North Fairview Ave',\n         'North Rose Ave',\n         'Petit Ave',\n         'Rose Ave',\n         'S Victoria Ave',\n         'South Victoria Ave',\n         'Ventura Ave',\n         'Vineyard Ave',\n         'West Ocean Ave'},\n 'Beach': {'The Beach'},\n 'Blvd': {'Thompson Blvd', 'E Thompson Blvd', 'Harbor Blvd'},\n 'Blvd.': {'East Thompson Blvd.'},\n 'Ciervo': {'Vereda del Ciervo'},\n 'Circle': {'Bluefin Circle'},\n 'Dr': {'Citrus Dr',\n        'Daytona Dr',\n        'Johnson Dr',\n        'Mathilda Dr',\n        'Seagull Dr',\n        'Spinnaker Dr'},\n 'Fairview': {'N. Fairview'},\n 'Hwy': {'1116 Maricopa Hwy'},\n 'Lindo': {'Camino Lindo'},\n 'Meta': {'E Meta'},\n 'Norte': {' Embarcadero del Norte', 'Embarcadero Del Norte'},\n 'Playa': {'Del Playa'},\n 'Rd': {'339 W Gonzales Rd',\n        'Loma Vista Rd',\n        'Pardall Rd',\n        'Pasado Rd',\n        'S Mills Rd',\n        'Telegraph Rd',\n        'Telephone Rd',\n        'Trigo Rd'},\n 'Rd.': {'S. Kimball Rd. at Telephone Rd.', 'San Ysidro Rd.'},\n 'Real': {'Calle Real'},\n 'Seaward': {'S Seaward'},\n 'St': {'E Main St',\n        'Garden St',\n        'Main St',\n        'Oak St',\n        'Violeta St',\n        'W Main St',\n        '\\u200e3687 Sagunto St'},\n 'St.': {'W. Micheltorena St.', 'N. Milpas St.'},\n 'Tarde': {'Sabado Tarde'},\n 'Trigo': {'Trigo'},\n 'Vista': {'Loma Vista'},\n 'Way': {'Greggory Way', 'Portico Way', 'Industrial Way', 'Seaglass Way'}}\n"}], "cell_type": "code"}, {"source": "#Mapping to correct street types\nmapping = { \"St.\": \"Street\", \"St\": \"Street\",\n            \"Ave.\": \"Avenue\", \"Ave\": \"Avenue\",\n            \"Rd.\": \"Road\", \"Rd\": \"Road\",\n            \"W.\": \"West\", \"W\": \"West\",\n            \"N.\": \"North\", \"N\": \"North\",\n            \"S.\": \"South\", \"S\": \"South\",\n            \"E.\": \"East\", \"E\": \"East\",\n            \"Dr.\": \"Drive\", \"Dr\": \"Drive\",\n            \"Blvd.\": \"Boulevard\", \"Blvd\": \"Boulevard\",\n            \"Hwy\": \"Highway\",\n            \"del\": \"Del\"}\n\n#Mapping to correct other errors noticed in manual scan of data\nmanual_mapping = {\" Embarcadero del Norte\": \"Embarcadero Del Norte\",\n                  \"Hwy 33 PM 30.12\": \"Highway 33\",\n                  \"1116 Maricopa Hwy\": \"Maricopa Highway\",\n                  \"339 W Gonzales Rd\": \"West Gonzales Road\",\n                  \"\\u200e3687 Sagunto St\": \"Sagunto Street\",\n                  \"721 Jonata Park Road\": \"Jonata Park Road\",\n                  \"400 Storke Road\": \"Storke Road\",\n                  \"3999 State Street\": \"State Street\",\n                  \"301 West Front Street\": \"West Front Street\",\n                  \"Trigo\": \"Trigo Road\",\n                  \"Loma Vista\": \"Loma Vista Avenue\",\n                  \"Sabado Tarde\": \"Sabado Tarde Road\",\n                  \"S Seaward\": \"South Seaward Drive\",\n                  \"Del Playa\": \"Del Playa Drive\",\n                  \"N. Fairview\": \"North Fairview Avenue\",\n                  \"Abrego\": \"Abrego Street\"}\n\ndef update_name(name, mapping, manual_mapping):  \n    \"\"\"Updates street names based on mapping above\"\"\"\n    if name in manual_mapping.keys():\n        name = manual_mapping[name]\n        return name\n    else:\n        new_name = []\n        for part in name.split(\" \"):\n            if part in mapping.keys():\n                part = mapping[part]\n            new_name.append(part)\n            \n        return \" \".join(new_name)\n\n\ndef test_update_name():\n    for st_type, ways in street_types.items():\n        for name in ways:\n            better_name = update_name(name, mapping, manual_mapping)\n            print(name, \"=>\", better_name)\n            \n            \ntest_update_name()", "metadata": {"collapsed": false, "trusted": true, "scrolled": true}, "execution_count": 3, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Loma Vista => Loma Vista Avenue\nVereda del Ciervo => Vereda Del Ciervo\n Embarcadero del Norte => Embarcadero Del Norte\nEmbarcadero Del Norte => Embarcadero Del Norte\nS. Kimball Rd. at Telephone Rd. => South Kimball Road at Telephone Road\nSan Ysidro Rd. => San Ysidro Road\nDel Playa => Del Playa Drive\nCalle Real => Calle Real\nAbrego => Abrego Street\nThe Beach => The Beach\nNorth Highway 101 => North Highway 101\nJohnson Dr => Johnson Drive\nSpinnaker Dr => Spinnaker Drive\nMathilda Dr => Mathilda Drive\nDaytona Dr => Daytona Drive\nCitrus Dr => Citrus Drive\nSeagull Dr => Seagull Drive\nGreggory Way => Greggory Way\nPortico Way => Portico Way\nIndustrial Way => Industrial Way\nSeaglass Way => Seaglass Way\nW Main St => West Main Street\n\u200e3687 Sagunto St => Sagunto Street\nGarden St => Garden Street\nOak St => Oak Street\nE Main St => East Main Street\nVioleta St => Violeta Street\nMain St => Main Street\nHwy 33 PM 30.12 => Highway 33\nPardall Rd => Pardall Road\nS Mills Rd => South Mills Road\nLoma Vista Rd => Loma Vista Road\nPasado Rd => Pasado Road\nTelegraph Rd => Telegraph Road\n339 W Gonzales Rd => West Gonzales Road\nTelephone Rd => Telephone Road\nTrigo Rd => Trigo Road\nThompson Blvd => Thompson Boulevard\nE Thompson Blvd => East Thompson Boulevard\nHarbor Blvd => Harbor Boulevard\nS Seaward => South Seaward Drive\nN. Fairview => North Fairview Avenue\nJct Of Sr 246 & Sr 154 => Jct Of Sr 246 & Sr 154\nEast Thompson Blvd. => East Thompson Boulevard\nTrigo => Trigo Road\nCamino Lindo => Camino Lindo\nBluefin Circle => Bluefin Circle\nW. Micheltorena St. => West Micheltorena Street\nN. Milpas St. => North Milpas Street\nN Ashwood Ave => North Ashwood Avenue\nLinden Ave => Linden Avenue\nLillie Ave => Lillie Avenue\nS Victoria Ave => South Victoria Avenue\nVentura Ave => Ventura Avenue\nRose Ave => Rose Avenue\nNorth Rose Ave => North Rose Avenue\nN Ventura Ave => North Ventura Avenue\nNorth Fairview Ave => North Fairview Avenue\nLos Angeles Ave => Los Angeles Avenue\nSouth Victoria Ave => South Victoria Avenue\nVineyard Ave => Vineyard Avenue\nPetit Ave => Petit Avenue\nWest Ocean Ave => West Ocean Avenue\nSabado Tarde => Sabado Tarde Road\n1116 Maricopa Hwy => Maricopa Highway\nE Meta => East Meta\n"}], "cell_type": "code"}, {"source": "\"\"\"\nFurther examination of the Postal Codes in the OSM file in order to audit and correct\nany errors.\n\"\"\"\n\n#All tags representing Postal Codes discovered earlier in tag audit\nZIPCODE_TAGS = ['addr:postcode', 'tiger:zip_left', 'tiger:zip_left_1', 'tiger:zip_left_2', \n                'tiger:zip_left_3', 'tiger:zip_left_4', 'tiger:zip_right', 'tiger:zip_right_1',\n                'tiger:zip_right_2', 'tiger:zip_right_3', 'tiger:zip_right_4']\n\ndef is_postal_code(elem):\n    return (elem.attrib['k'] in ZIPCODE_TAGS)\n\n\ndef audit_postal_codes(osmfile):\n    \"\"\"Audit OSM file to find Postal Codes that do not being with 93 and are not length 5\"\"\"\n    osm_file = open(osmfile, \"r\", encoding=\"utf8\")\n    postal_codes = {}\n    \n    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n        if elem.tag == \"node\" or elem.tag == \"way\":\n            for tag in elem.iter(\"tag\"):\n                if is_postal_code(tag):\n                    if postal_code_re.search(tag.attrib['v']) or postal_code_re2.search(tag.attrib['v']) or not tag.attrib['v'].startswith('93'):\n                        if tag.attrib['v'] not in postal_codes:\n                            postal_codes[tag.attrib['v']] = 1\n                        else:\n                            postal_codes[tag.attrib['v']] += 1\n                        \n    return postal_codes\n\n\npostal_codes = audit_postal_codes(FILENAME)\nprint(postal_codes)", "metadata": {"collapsed": false, "trusted": true}, "execution_count": 4, "outputs": [{"name": "stdout", "output_type": "stream", "text": "{'93001:93003': 4, '93033-3245': 1, '93030-5236': 1, '3701': 1, '93013:93108': 3, '93036-2007': 1, '93101:93110': 2, '93033-7671': 1}\n"}], "cell_type": "code"}, {"source": "#Mapping to correct error \"3701\" correct postal code researched manually.\ncode_mapping = {\"3701\": \"93105\"}\n\ndef update_postal_codes(postal, mapping):\n    \"\"\"Update postal codes programmatically and with mapping as necessary\"\"\"\n    m = postal_code_re.search(postal)\n    m2 = postal_code_re2.search(postal)\n    \n    if postal in mapping.keys():\n        postal = mapping[postal]\n    elif m:\n        postal = m.group(1)\n    elif m2:\n        postal = m2.group(1)\n    else:\n        postal = postal\n    \n    return postal\n\n        \ndef test_update_postal_codes():\n    for code in postal_codes.keys():\n        better_code = update_postal_codes(code, code_mapping)\n        print(code, \"=>\", better_code)\n                    \n            \ntest_update_postal_codes()", "metadata": {"collapsed": false, "trusted": true}, "execution_count": 5, "outputs": [{"name": "stdout", "output_type": "stream", "text": "93001:93003 => 93001\n93033-3245 => 93033\n93030-5236 => 93030\n3701 => 93105\n93013:93108 => 93013\n93036-2007 => 93036\n93101:93110 => 93101\n93033-7671 => 93033\n"}], "cell_type": "code"}, {"source": "\n\"\"\"\nYour task is to wrangle the data and transform the shape of the data\ninto the model we mentioned earlier. The output should be a list of dictionaries\nthat look like this:\n\n{\n\"id\": \"2406124091\",\n\"type: \"node\",\n\"visible\":\"true\",\n\"created\": {\n          \"version\":\"2\",\n          \"changeset\":\"17206049\",\n          \"timestamp\":\"2013-08-03T16:43:42Z\",\n          \"user\":\"linuxUser16\",\n          \"uid\":\"1219059\"\n        },\n\"pos\": [41.9757030, -87.6921867],\n\"address\": {\n          \"housenumber\": \"5157\",\n          \"postcode\": \"60625\",\n          \"street\": \"North Lincoln Ave\"\n        },\n\"amenity\": \"restaurant\",\n\"cuisine\": \"mexican\",\n\"name\": \"La Cabana De Don Luis\",\n\"phone\": \"1 (773)-271-5176\"\n}\n\nYou have to complete the function 'shape_element'.\nWe have provided a function that will parse the map file, and call the function with the element\nas an argument. You should return a dictionary, containing the shaped data for that element.\nWe have also provided a way to save the data in a file, so that you could use\nmongoimport later on to import the shaped data into MongoDB. \n\nNote that in this exercise we do not use the 'update street name' procedures\nyou worked on in the previous exercise. If you are using this code in your final\nproject, you are strongly encouraged to use the code from previous exercise to \nupdate the street names before you save them to JSON. \n\nIn particular the following things should be done:\n- you should process only 2 types of top level tags: \"node\" and \"way\"\n- all attributes of \"node\" and \"way\" should be turned into regular key/value pairs, except:\n    - attributes in the CREATED array should be added under a key \"created\"\n    - attributes for latitude and longitude should be added to a \"pos\" array,\n      for use in geospacial indexing. Make sure the values inside \"pos\" array are floats\n      and not strings. \n- if second level tag \"k\" value contains problematic characters, it should be ignored\n- if second level tag \"k\" value starts with \"addr:\", it should be added to a dictionary \"address\"\n- if second level tag \"k\" value does not start with \"addr:\", but contains \":\", you can process it\n  same as any other tag.\n- if there is a second \":\" that separates the type/direction of a street,\n  the tag should be ignored, for example:\n\n<tag k=\"addr:housenumber\" v=\"5158\"/>\n<tag k=\"addr:street\" v=\"North Lincoln Avenue\"/>\n<tag k=\"addr:street:name\" v=\"Lincoln\"/>\n<tag k=\"addr:street:prefix\" v=\"North\"/>\n<tag k=\"addr:street:type\" v=\"Avenue\"/>\n<tag k=\"amenity\" v=\"pharmacy\"/>\n\n  should be turned into:\n\n{...\n\"address\": {\n    \"housenumber\": 5158,\n    \"street\": \"North Lincoln Avenue\"\n}\n\"amenity\": \"pharmacy\",\n...\n}\n\n- for \"way\" specifically:\n\n  <nd ref=\"305896090\"/>\n  <nd ref=\"1719825889\"/>\n\nshould be turned into\n\"node_refs\": [\"305896090\", \"1719825889\"]\n\"\"\"\n\nCREATED = [ \"version\", \"changeset\", \"timestamp\", \"user\", \"uid\"]\n\ndef is_address(elem):\n    \"\"\"Return true if tag start with 'addr:'\"\"\"\n    if elem.attrib['k'][:5] == \"addr:\":\n        return True\n    \n\ndef shape_element(element):\n    \"\"\"Process and shape data\"\"\"\n    node = {}\n    node[\"created\"]={}\n    node[\"address\"]={}\n    node[\"pos\"]=[]\n    refs=[]\n    \n    #Only process the node and way tags\n    if element.tag == \"node\" or element.tag == \"way\":\n        if \"id\" in element.attrib:\n            node[\"id\"] = element.attrib[\"id\"]           \n        node[\"type\"] = element.tag\n        \n        #Add visible were available\n        if \"visible\" in element.attrib.keys():\n            node[\"visible\"] = element.attrib[\"visible\"]\n      \n        #Add values for the CREATED feild\n        for elem in CREATED:\n            if elem in element.attrib:\n                node[\"created\"][elem]=element.attrib[elem]\n                \n        #Add values for latitude and longitute      \n        if \"lat\" in element.attrib:\n            node[\"pos\"].append(float(element.attrib[\"lat\"]))\n    \n        if \"lon\" in element.attrib:\n            node[\"pos\"].append(float(element.attrib[\"lon\"]))\n\n        #Iterate through subtags\n        for tag in element.iter(\"tag\"):\n            #Ignore problem characters\n            if problemchars.search(tag.attrib['k']):\n                continue\n            \n            #Add housenumber values\n            if tag.attrib['k'] == \"addr:housenumber\":\n                node[\"address\"][\"housenumber\"]= tag.attrib['v']\n            \n            #Add and update postal code values\n            if is_postal_code(tag):\n                node[\"address\"][\"postcode\"]= tag.attrib['v']\n                node[\"address\"][\"postcode\"]= update_postal_codes(node[\"address\"][\"postcode\"], code_mapping)\n                \n            #Add and update street name values  \n            if is_street_name(tag):\n                node[\"address\"][\"street\"]= tag.attrib['v']\n                node[\"address\"][\"street\"]= update_name(node[\"address\"][\"street\"], mapping, manual_mapping)\n\n            #Add values for non-address, non-postal tags that don't include \":\"\n            if not is_address(tag) and not is_postal_code(tag) and (\":\" not in tag.attrib['k']):\n                node[tag.attrib['k']]=tag.attrib['v']\n\n        #Extract node reference values\n        for nd in element.iter(\"nd\"):\n             refs.append(nd.attrib[\"ref\"])\n        \n        #Remove empty addresses\n        if node[\"address\"] == {}:\n            node.pop(\"address\", None)\n\n        #Add node reference values\n        if refs != []:\n           node[\"node_refs\"]=refs\n            \n        return node\n    else:\n        return None\n\n\ndef process_map(file_in, pretty = False):\n    file_out = \"{0}.json\".format(file_in)\n    data = []\n    with codecs.open(file_out, \"w\") as fo:\n        for _, element in ET.iterparse(file_in):\n            el = shape_element(element)\n            if el:\n                data.append(el)\n                if pretty:\n                    fo.write(json.dumps(el, indent=2)+\"\\n\")\n                else:\n                    fo.write(json.dumps(el) + \"\\n\")\n    \n    print(\"Complete\")\n    return data\n\n\nJSONdata = process_map(FILENAME, False)", "metadata": {"collapsed": false, "trusted": true}, "execution_count": 6, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Complete\n"}], "cell_type": "code"}, {"source": "\"\"\"\nTransfer the recenty created JSON file into MongoDB\nusing PyMongo. Create mongodbproject database and SB collection.\n\"\"\"\n\ndef get_db(db_name):\n    client = MongoClient(\"mongodb://localhost:27017\")\n    db = client[db_name]\n    return db\n    \n    \ndef get_collection(db, collection):\n    collections_db = db[collection]\n    return collections_db\n    \n\ndef insert_data(json_data, db_collection):\n    \"\"\"Insert the JSON data file into MongoDB\"\"\"\n    with open(json_data, 'r') as f:\n        for each_line in f.readlines():\n            db_collection.insert(json.loads(each_line))\n    print(\"Complete\")\n\n    \n#Set up database and collection\ndb = get_db('mongodbproject')\ndb_SB = get_collection(db, 'SB')\n\n\ninsert_data(FILENAMEJSON, db_SB)", "metadata": {"collapsed": false, "trusted": true}, "execution_count": 7, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Complete\n"}], "cell_type": "code"}, {"source": "\"\"\"\nData Overview for MongoDB collection\n\"\"\"\n\n#File sizes\nprint(\"santabarbara.osm size:\", os.path.getsize(FILENAME)/1024/1024)\nprint(\"santabarbara.osm.json size:\", os.path.getsize(FILENAMEJSON)/1024/1024)\n\n#Documents\nprint(\"# of documents:\", db_SB.find().count())\n\n#Nodes\nprint(\"# of nodes:\", db_SB.find({\"type\":\"node\"}).count())\n\n#Ways\nprint(\"# of ways:\", db_SB.find({\"type\":\"way\"}).count())\n      \n#Unique users\nprint(\"# of unique users:\", len(db_SB.distinct(\"created.user\")))\n\n#Universites\nprint(\"# of universities:\", db_SB.find({\"amenity\":\"university\"}).count())", "metadata": {"collapsed": false, "trusted": true, "scrolled": true}, "execution_count": 8, "outputs": [{"name": "stdout", "output_type": "stream", "text": "santabarbara.osm size: 165.2511863708496\nsantabarbara.osm.json size: 180.91535091400146\n# of documents: 872632\n# of nodes: 836092\n# of ways: 36497\n# of unique users: 292\n# of universities: 18\n"}], "cell_type": "code"}, {"source": "\"\"\"\nFurther analysis of the MongoDB collection using PyMongo\n\"\"\"\n\n#Aggregation operations return a cursor object\n#Iterate over in order to print out one by one\ndef agg_print(result):\n    for item in result:\n        print(item)\n        \n#User Contributions        \npipeline = [{\"$group\":{\"_id\": \"$created.user\",\n                       \"count\": {\"$sum\": 1}}},\n            {\"$project\": {\"proportion\": {\"$divide\" :[\"$count\",db_SB.find().count()]}}},\n            {\"$sort\": {\"proportion\": -1}},\n            {\"$limit\": 3}]\nresult = db_SB.aggregate(pipeline)\nprint(\"Proportions of top users' contributions:\")\nagg_print(result)\n\n\n#Amenities\npipeline = [{\"$match\":{\"amenity\":{\"$exists\":1}}},\n            {\"$group\":{\"_id\":\"$amenity\", \"count\":{\"$sum\":1}}},\n            {\"$sort\":{\"count\":-1}},\n            {\"$limit\":10}]\nresult = db_SB.aggregate(pipeline)\nprint(\"Top 10 appearing amenities:\")\nagg_print(result)\n\n\n#Cuisines\npipeline = [{\"$match\":{\"amenity\":{\"$exists\":1}, \"amenity\":\"restaurant\", \"cuisine\":{\"$exists\":1}}}, \n            {\"$group\":{\"_id\":\"$cuisine\", \"count\":{\"$sum\":1}}},        \n            {\"$sort\":{\"count\":-1}}, \n            {\"$limit\":10}]\nresult = db_SB.aggregate(pipeline)\nprint(\"Most popular cuisines:\")\nagg_print(result)\n\n\n#Universities\npipeline = [{\"$match\":{\"amenity\":{\"$exists\":1}, \"amenity\": \"university\", \"name\":{\"$exists\":1}}},\n            {\"$group\":{\"_id\":\"$name\", \"count\":{\"$sum\":1}}},\n            {\"$sort\":{\"count\":-1}}]\nresult = db_SB.aggregate(pipeline)\nprint(\"Universities:\")\nagg_print(result)", "metadata": {"collapsed": false, "trusted": true, "scrolled": true}, "execution_count": 9, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Proportions of top users' contributions:\n{'proportion': 0.3944824393329605, '_id': 'woodpeck_fixbot'}\n{'proportion': 0.138180813905518, '_id': 'nmixter'}\n{'proportion': 0.09071063174396539, '_id': 'Apo42'}\nTop 10 appearing amenities:\n{'count': 346, '_id': 'parking'}\n{'count': 320, '_id': 'school'}\n{'count': 306, '_id': 'place_of_worship'}\n{'count': 95, '_id': 'telephone'}\n{'count': 94, '_id': 'restaurant'}\n{'count': 82, '_id': 'fast_food'}\n{'count': 57, '_id': 'bicycle_parking'}\n{'count': 45, '_id': 'fire_station'}\n{'count': 41, '_id': 'fuel'}\n{'count': 41, '_id': 'toilets'}\nMost popular cuisines:\n{'count': 11, '_id': 'american'}\n{'count': 5, '_id': 'seafood'}\n{'count': 5, '_id': 'pizza'}\n{'count': 5, '_id': 'mexican'}\n{'count': 3, '_id': 'thai'}\n{'count': 3, '_id': 'burger'}\n{'count': 2, '_id': 'chinese'}\n{'count': 2, '_id': 'sushi'}\n{'count': 2, '_id': 'brazilian'}\n{'count': 2, '_id': 'sandwich'}\nUniversities:\n{'count': 1, '_id': 'Jacobs Hall'}\n{'count': 1, '_id': 'National University'}\n{'count': 1, '_id': 'University of California, Santa Barbara Storke Campus'}\n{'count': 1, '_id': 'Santa Barbara City College'}\n{'count': 1, '_id': 'Isla Vista Theater'}\n{'count': 1, '_id': 'Embarcadero Hall'}\n{'count': 1, '_id': 'University of California, Santa Barbara West Campus'}\n{'count': 1, '_id': 'University of California, Santa Barbara Main Campus'}\n{'count': 1, '_id': 'University of California - Santa Barbara'}\n"}], "cell_type": "code"}, {"source": "\"\"\"\nReview of Postal Code and Street corrections\n\"\"\"\n\n#Postal codes\npipeline = [{\"$group\":{\"_id\": \"$address.postcode\",\n                       \"count\": {\"$sum\": 1}}},\n            {\"$sort\": {\"count\": -1}}]\nresult = db_SB.aggregate(pipeline)\nprint(\"Postal codes:\")\nagg_print(result)\n\n\n#Streets\npipeline = [{\"$group\":{\"_id\": \"$address.street\",\n                       \"count\": {\"$sum\": 1}}},\n            {\"$sort\": {\"count\": -1}}]\nresult = db_SB.aggregate(pipeline)\nprint(\"Streets:\")\nagg_print(result)", "metadata": {"collapsed": false, "trusted": true, "scrolled": true}, "execution_count": null, "outputs": [], "cell_type": "code"}, {"source": "", "metadata": {"collapsed": true, "trusted": true}, "execution_count": null, "outputs": [], "cell_type": "code"}]}